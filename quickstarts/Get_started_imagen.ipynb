{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4N89t_88lb9"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "fXysRA_X8mX9"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ca92c014280"
      },
      "source": [
        "# Gemini API: Get started with image generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "621e235669c2"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_imagen.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-3T_Xet-QiB"
      },
      "source": [
        "The `imagen-3.0-generate-002` model is Google's highest quality text-to-image model, featuring a number of new and improved capabilities. Imagen 3 can do the following:\n",
        "\n",
        "* Generate images with fine detail, rich lighting, and few distracting artifact\n",
        "* Understand prompts written in natural language\n",
        "* Generate images in a wide range of formats and styles\n",
        "* Render text effectively\n",
        "\n",
        "This notebook is using the [Python SDK](https://googleapis.github.io/python-genai/#imagen). For the REST API, check out the [Get Started with Imagen](../Get_started_imagen_rest.ipynb) guide.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shEdTt34HNvR"
      },
      "source": [
        "<!-- Warning Badge -->\n",
        "<table>\n",
        "  <tr>\n",
        "    <!-- Emoji -->\n",
        "    <td bgcolor=\"#f5949e\">\n",
        "      <font size=30>⚠️</font>\n",
        "    </td>\n",
        "    <!-- Text Content Cell -->\n",
        "    <td bgcolor=\"#f5949e\">\n",
        "      <h3><font color=black>Image generation is a paid-only feature and won't work if you are on the free tier. Check the <a href=\"https://ai.google.dev/pricing#imagen-4\"><font color='#217bfe'>pricing</font></a> page for more details.</font></h3>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfk6YY3G5kqp"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5027929de8f"
      },
      "source": [
        "### Install SDK\n",
        "\n",
        "Install the SDK from [PyPI](https://github.com/googleapis/python-genai)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "46zEFO2a9FFd"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U \"google-genai>=1.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTIfnvCn9HvH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A1pkoyZb9Jm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "4e069594-d21c-4c72-ee42-8c8b82974484"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret GOOGLE_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-2448054115.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mGOOGLE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GOOGLE_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret GOOGLE_API_KEY does not exist."
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hx_Gw9i0Yuv"
      },
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK you now only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HghvVpbU0Uap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "6c70a9fa-c9ff-4cfb-f350-199a4a47ed7f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GOOGLE_API_KEY' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-391063894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'GOOGLE_API_KEY' is not defined"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cFFYhIkFYMk"
      },
      "source": [
        "## Generate images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6beK92bH2qm"
      },
      "source": [
        "### Select model\n",
        "\n",
        "There are currently 3 available Imagen models:\n",
        "* Imagen 4 (`imagen-4.0-generate-preview-06-06`) is the new stadard model you should use to generate.\n",
        "* Imagen 4 Ultra (`imagen-4.0-ultra-generate-preview-06-06`) is the best Imagen model, generating even finer images and is especially good at generating images with text. Note that it can only generate one image at a time.\n",
        "* Imagen 3 (`imagen-3.0-generate-002`) is the previous generation model. It's still available in case you need to rerun old prompts, but it is recommended to use the 4th generation models now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IJ8Vf9RVFeDi"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"imagen-4.0-generate-preview-06-06\" # @param [\"imagen-3.0-generate-002\",\"imagen-4.0-generate-preview-06-06\",\"imagen-4.0-ultra-generate-preview-06-06\"] {\"allow-input\":true}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df9FUZgHH3oD"
      },
      "source": [
        "### Prompt creation\n",
        "\n",
        "Now, write your prompt and set some optional parameters. The `imagen-3.0-generate-002` model is trained on long captions and will provide better results for longer and more descriptive prompts. Note that if you use a short prompt, it may result in low adherence and more random output.\n",
        "\n",
        "Check the [prompt guide](https://ai.google.dev/gemini-api/docs/imagen-prompt-guide) for more advice on creating your prompts.\n",
        "\n",
        "Here are the parameters you can set relating to your prompt:\n",
        "* `number_of_images`: Specifies how many iamges will be generated. The default value is 4, with valid values between 1 to 4, inclusive. In the below code cell, `sample_count` is used to define this.\n",
        "* `person_generation`: Allows the model to generate images with adults. Kids are always blocked. The supported values are `DONT_ALLOW` and `ALLOW_ADULT`. The default value is `ALLOW_ADULT`.\n",
        "* `aspect_ratio`: Specifies the aspect ratio of the images produces. The supported values are `1:1`, `3:4`, `4:3`, `16:9`, and `9:16`. The default value is `1:1`.\n",
        "* `output_mime_type`: The output type of your image, which will be `image/jpeg`. This is the only allowed value at the moment.\n",
        "\n",
        "A non-visible digital [SynthID](https://deepmind.google/technologies/synthid/) watermark is always added to generated images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P4d8y2p_LBfK"
      },
      "outputs": [],
      "source": [
        "prompt = \"A cat lounging lazily on a sunny windowstill playing with a kid toy.\" # @param {type:\"string\"}\n",
        "number_of_images = 1 # @param {type:\"slider\", min:1, max:4, step:1}\n",
        "person_generation = \"ALLOW_ADULT\" # @param ['DONT_ALLOW', 'ALLOW_ADULT']\n",
        "aspect_ratio = \"1:1\" # @param [\"1:1\", \"3:4\", \"4:3\", \"16:9\", \"9:16\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP5ZWWIMJBPr"
      },
      "source": [
        "### Generate the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TM6oJ0YOLEFG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b2a90a0f-8356-4eda-8b05-dbd1ac99c1f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-3354529126.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result = client.models.generate_images(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     config=dict(\n\u001b[1;32m      5\u001b[0m         \u001b[0mnumber_of_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ],
      "source": [
        "result = client.models.generate_images(\n",
        "    model=MODEL_ID,\n",
        "    prompt=prompt,\n",
        "    config=dict(\n",
        "        number_of_images=number_of_images,\n",
        "        output_mime_type=\"image/jpeg\",\n",
        "        person_generation=person_generation,\n",
        "        aspect_ratio=aspect_ratio\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6KkjzySMJaS"
      },
      "source": [
        "### Display the images\n",
        "\n",
        "Use the code below to inspect the images you generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBtTVgLpMED3"
      },
      "outputs": [],
      "source": [
        "for generated_image in result.generated_images:\n",
        "  image = generated_image.image.show()\n",
        "\n",
        "# Outside of Colab, you'll need to use those libraries to open the images\n",
        "# from PIL import Image\n",
        "# from io import BytesIO\n",
        "# for generated_image in result.generated_images:\n",
        "#   image = Image.open(BytesIO(generated_image.image.image_bytes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sP88688clr6"
      },
      "source": [
        "## Generate images with text\n",
        "\n",
        "Imagen 3 and 4 models are good at generating images with text. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMTvcpwtczXk",
        "outputId": "993b9cc4-d641-414a-8a53-10dc1c703158"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "Output hidden; open in https://colab.research.google.com to view."
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"A colorful birthday cake looking like a unicorn, with a sign that says \\\"Happy birthday Aurore!\\\"\" # @param {type:\"string\"}\n",
        "number_of_images = 1 # @param {type:\"slider\", min:1, max:4, step:1}\n",
        "person_generation = \"ALLOW_ADULT\" # @param ['DONT_ALLOW', 'ALLOW_ADULT']\n",
        "aspect_ratio = \"1:1\" # @param [\"1:1\", \"3:4\", \"4:3\", \"16:9\", \"9:16\"]\n",
        "\n",
        "result = client.models.generate_images(\n",
        "    model=MODEL_ID,\n",
        "    prompt=prompt,\n",
        "    config=dict(\n",
        "        number_of_images=number_of_images,\n",
        "        output_mime_type=\"image/jpeg\",\n",
        "        person_generation=person_generation,\n",
        "        aspect_ratio=aspect_ratio\n",
        "    )\n",
        ")\n",
        "\n",
        "for generated_image in result.generated_images:\n",
        "  image = generated_image.image.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YjhMPpAgBtf"
      },
      "source": [
        "Here's a second one. This time, the image saved in the notebook has been generated using Imagen 4 Ultra as there was quite a lot of text to process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj_fG002fHxq",
        "outputId": "5e2191ca-d801-4eeb-be88-b3cde4404877"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "Output hidden; open in https://colab.research.google.com to view."
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"a wall on which a colorful tag is drawn along with the first verse of Charles Baudelaire's poem \\\"l'invitation au voyage\\\": Mon enfant, ma sœur,    Songe à la douceur  D’aller là-bas vivre ensemble !    Aimer à loisir,    Aimer et mourir  Au pays qui te ressemble !\" # @param {type:\"string\"}\n",
        "number_of_images = 1 # @param {type:\"slider\", min:1, max:4, step:1}\n",
        "person_generation = \"ALLOW_ADULT\" # @param ['DONT_ALLOW', 'ALLOW_ADULT']\n",
        "aspect_ratio = \"9:16\" # @param [\"1:1\", \"3:4\", \"4:3\", \"16:9\", \"9:16\"]\n",
        "\n",
        "result = client.models.generate_images(\n",
        "    model=MODEL_ID,\n",
        "    prompt=prompt,\n",
        "    config=dict(\n",
        "        number_of_images=number_of_images,\n",
        "        output_mime_type=\"image/jpeg\",\n",
        "        person_generation=person_generation,\n",
        "        aspect_ratio=aspect_ratio\n",
        "    )\n",
        ")\n",
        "\n",
        "for generated_image in result.generated_images:\n",
        "  image = generated_image.image.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFl3Hlc8NPdr"
      },
      "source": [
        "## Next Steps\n",
        "### Useful documentation references:\n",
        "\n",
        "To improve your prompting skills, check the [prompt guide](https://ai.google.dev/gemini-api/docs/imagen-prompt-guide) for great advices on creating your prompts.\n",
        "\n",
        "### Check those cool Imagen examples:\n",
        "Here are some Imagen examples to get your imagination started on how to use it in creative ways:\n",
        "*  [Illustrate a book](../examples/Book_illustration.ipynb): Use Gemini and Imagen to create illustration for an open-source book\n",
        "\n",
        "### Continue your discovery of the Gemini API\n",
        "\n",
        "Gemini is not only good at generating images, but also at understanding them. Check the [Spatial understanding](./Spatial_understanding.ipynb) guide for an introduction on those capabilities, and the [Video understanding](./Video_understanding.ipynb) one for video examples.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "j4N89t_88lb9"
      ],
      "name": "Get_started_imagen.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}